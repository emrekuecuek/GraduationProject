{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian Credit Approval Statlog\n",
    "\n",
    "Applying algorithms in R for given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data and assigning it to myData variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(e1071)\n",
    "library(caret)\n",
    "library(BalancedSampling)\n",
    "\n",
    "myData <- read.csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat\", header=FALSE, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1     </td><td>22.08 </td><td>11.460</td><td>2     </td><td>4     </td><td>4     </td><td>1.585 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>100   </td><td>1213  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>22.67 </td><td> 7.000</td><td>2     </td><td>8     </td><td>4     </td><td>0.165 </td><td>0     </td><td>0     </td><td> 0    </td><td>0     </td><td>2     </td><td>160   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>29.58 </td><td> 1.750</td><td>1     </td><td>4     </td><td>4     </td><td>1.250 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>280   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>21.67 </td><td>11.500</td><td>1     </td><td>5     </td><td>3     </td><td>0.000 </td><td>1     </td><td>1     </td><td>11    </td><td>1     </td><td>2     </td><td>  0   </td><td>   1  </td><td>1     </td></tr>\n",
       "\t<tr><td>1     </td><td>20.17 </td><td> 8.170</td><td>2     </td><td>6     </td><td>4     </td><td>1.960 </td><td>1     </td><td>1     </td><td>14    </td><td>0     </td><td>2     </td><td> 60   </td><td> 159  </td><td>1     </td></tr>\n",
       "\t<tr><td>0     </td><td>15.83 </td><td> 0.585</td><td>2     </td><td>8     </td><td>8     </td><td>1.500 </td><td>1     </td><td>1     </td><td> 2    </td><td>0     </td><td>2     </td><td>100   </td><td>   1  </td><td>1     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & V12 & V13 & V14 & V15\\\\\n",
       "\\hline\n",
       "\t 1      & 22.08  & 11.460 & 2      & 4      & 4      & 1.585  & 0      & 0      &  0     & 1      & 2      & 100    & 1213   & 0     \\\\\n",
       "\t 0      & 22.67  &  7.000 & 2      & 8      & 4      & 0.165  & 0      & 0      &  0     & 0      & 2      & 160    &    1   & 0     \\\\\n",
       "\t 0      & 29.58  &  1.750 & 1      & 4      & 4      & 1.250  & 0      & 0      &  0     & 1      & 2      & 280    &    1   & 0     \\\\\n",
       "\t 0      & 21.67  & 11.500 & 1      & 5      & 3      & 0.000  & 1      & 1      & 11     & 1      & 2      &   0    &    1   & 1     \\\\\n",
       "\t 1      & 20.17  &  8.170 & 2      & 6      & 4      & 1.960  & 1      & 1      & 14     & 0      & 2      &  60    &  159   & 1     \\\\\n",
       "\t 0      & 15.83  &  0.585 & 2      & 8      & 8      & 1.500  & 1      & 1      &  2     & 0      & 2      & 100    &    1   & 1     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 | V12 | V13 | V14 | V15 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1      | 22.08  | 11.460 | 2      | 4      | 4      | 1.585  | 0      | 0      |  0     | 1      | 2      | 100    | 1213   | 0      |\n",
       "| 0      | 22.67  |  7.000 | 2      | 8      | 4      | 0.165  | 0      | 0      |  0     | 0      | 2      | 160    |    1   | 0      |\n",
       "| 0      | 29.58  |  1.750 | 1      | 4      | 4      | 1.250  | 0      | 0      |  0     | 1      | 2      | 280    |    1   | 0      |\n",
       "| 0      | 21.67  | 11.500 | 1      | 5      | 3      | 0.000  | 1      | 1      | 11     | 1      | 2      |   0    |    1   | 1      |\n",
       "| 1      | 20.17  |  8.170 | 2      | 6      | 4      | 1.960  | 1      | 1      | 14     | 0      | 2      |  60    |  159   | 1      |\n",
       "| 0      | 15.83  |  0.585 | 2      | 8      | 8      | 1.500  | 1      | 1      |  2     | 0      | 2      | 100    |    1   | 1      |\n",
       "\n"
      ],
      "text/plain": [
       "  V1 V2    V3     V4 V5 V6 V7    V8 V9 V10 V11 V12 V13 V14  V15\n",
       "1 1  22.08 11.460 2  4  4  1.585 0  0   0  1   2   100 1213 0  \n",
       "2 0  22.67  7.000 2  8  4  0.165 0  0   0  0   2   160    1 0  \n",
       "3 0  29.58  1.750 1  4  4  1.250 0  0   0  1   2   280    1 0  \n",
       "4 0  21.67 11.500 1  5  3  0.000 1  1  11  1   2     0    1 1  \n",
       "5 1  20.17  8.170 2  6  4  1.960 1  1  14  0   2    60  159 1  \n",
       "6 0  15.83  0.585 2  8  8  1.500 1  1   2  0   2   100    1 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(myData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Adjusments\n",
    "\n",
    "Adjusting dataset for categorical variables. Here R's factor function is used in order to tell R kernel that given certain columns should be treated as categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myData$V1 <- factor(myData$V1)\n",
    "myData$V4 <- factor(myData$V4)\n",
    "myData$V5 <- factor(myData$V5)\n",
    "myData$V6 <- factor(myData$V6)\n",
    "myData$V8 <- factor(myData$V8)\n",
    "myData$V9 <- factor(myData$V9)\n",
    "myData$V11 <- factor(myData$V11)\n",
    "myData$V12 <- factor(myData$V12)\n",
    "myData$V15 <- factor(myData$V15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1     </td><td>22.08 </td><td>11.460</td><td>2     </td><td>4     </td><td>4     </td><td>1.585 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>100   </td><td>1213  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>22.67 </td><td> 7.000</td><td>2     </td><td>8     </td><td>4     </td><td>0.165 </td><td>0     </td><td>0     </td><td> 0    </td><td>0     </td><td>2     </td><td>160   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>29.58 </td><td> 1.750</td><td>1     </td><td>4     </td><td>4     </td><td>1.250 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>280   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><td>0     </td><td>21.67 </td><td>11.500</td><td>1     </td><td>5     </td><td>3     </td><td>0.000 </td><td>1     </td><td>1     </td><td>11    </td><td>1     </td><td>2     </td><td>  0   </td><td>   1  </td><td>1     </td></tr>\n",
       "\t<tr><td>1     </td><td>20.17 </td><td> 8.170</td><td>2     </td><td>6     </td><td>4     </td><td>1.960 </td><td>1     </td><td>1     </td><td>14    </td><td>0     </td><td>2     </td><td> 60   </td><td> 159  </td><td>1     </td></tr>\n",
       "\t<tr><td>0     </td><td>15.83 </td><td> 0.585</td><td>2     </td><td>8     </td><td>8     </td><td>1.500 </td><td>1     </td><td>1     </td><td> 2    </td><td>0     </td><td>2     </td><td>100   </td><td>   1  </td><td>1     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & V12 & V13 & V14 & V15\\\\\n",
       "\\hline\n",
       "\t 1      & 22.08  & 11.460 & 2      & 4      & 4      & 1.585  & 0      & 0      &  0     & 1      & 2      & 100    & 1213   & 0     \\\\\n",
       "\t 0      & 22.67  &  7.000 & 2      & 8      & 4      & 0.165  & 0      & 0      &  0     & 0      & 2      & 160    &    1   & 0     \\\\\n",
       "\t 0      & 29.58  &  1.750 & 1      & 4      & 4      & 1.250  & 0      & 0      &  0     & 1      & 2      & 280    &    1   & 0     \\\\\n",
       "\t 0      & 21.67  & 11.500 & 1      & 5      & 3      & 0.000  & 1      & 1      & 11     & 1      & 2      &   0    &    1   & 1     \\\\\n",
       "\t 1      & 20.17  &  8.170 & 2      & 6      & 4      & 1.960  & 1      & 1      & 14     & 0      & 2      &  60    &  159   & 1     \\\\\n",
       "\t 0      & 15.83  &  0.585 & 2      & 8      & 8      & 1.500  & 1      & 1      &  2     & 0      & 2      & 100    &    1   & 1     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 | V12 | V13 | V14 | V15 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1      | 22.08  | 11.460 | 2      | 4      | 4      | 1.585  | 0      | 0      |  0     | 1      | 2      | 100    | 1213   | 0      |\n",
       "| 0      | 22.67  |  7.000 | 2      | 8      | 4      | 0.165  | 0      | 0      |  0     | 0      | 2      | 160    |    1   | 0      |\n",
       "| 0      | 29.58  |  1.750 | 1      | 4      | 4      | 1.250  | 0      | 0      |  0     | 1      | 2      | 280    |    1   | 0      |\n",
       "| 0      | 21.67  | 11.500 | 1      | 5      | 3      | 0.000  | 1      | 1      | 11     | 1      | 2      |   0    |    1   | 1      |\n",
       "| 1      | 20.17  |  8.170 | 2      | 6      | 4      | 1.960  | 1      | 1      | 14     | 0      | 2      |  60    |  159   | 1      |\n",
       "| 0      | 15.83  |  0.585 | 2      | 8      | 8      | 1.500  | 1      | 1      |  2     | 0      | 2      | 100    |    1   | 1      |\n",
       "\n"
      ],
      "text/plain": [
       "  V1 V2    V3     V4 V5 V6 V7    V8 V9 V10 V11 V12 V13 V14  V15\n",
       "1 1  22.08 11.460 2  4  4  1.585 0  0   0  1   2   100 1213 0  \n",
       "2 0  22.67  7.000 2  8  4  0.165 0  0   0  0   2   160    1 0  \n",
       "3 0  29.58  1.750 1  4  4  1.250 0  0   0  1   2   280    1 0  \n",
       "4 0  21.67 11.500 1  5  3  0.000 1  1  11  1   2     0    1 1  \n",
       "5 1  20.17  8.170 2  6  4  1.960 1  1  14  0   2    60  159 1  \n",
       "6 0  15.83  0.585 2  8  8  1.500 1  1   2  0   2   100    1 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(myData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After factorization, one should split their dataset to train and split parts. Here it is set as %75 train and %25 test according to their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(myData)\n",
    "test <- sample(1:n, n*0.25)\n",
    "train <- -test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Applications. Lets begin with taking a look to our train and test splits that we are going to use for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1     </td><td>22.08 </td><td>11.460</td><td>2     </td><td>4     </td><td>4     </td><td>1.585 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>100   </td><td>1213  </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0     </td><td>22.67 </td><td> 7.000</td><td>2     </td><td>8     </td><td>4     </td><td>0.165 </td><td>0     </td><td>0     </td><td> 0    </td><td>0     </td><td>2     </td><td>160   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0     </td><td>29.58 </td><td> 1.750</td><td>1     </td><td>4     </td><td>4     </td><td>1.250 </td><td>0     </td><td>0     </td><td> 0    </td><td>1     </td><td>2     </td><td>280   </td><td>   1  </td><td>0     </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1     </td><td>20.17 </td><td> 8.170</td><td>2     </td><td>6     </td><td>4     </td><td>1.960 </td><td>1     </td><td>1     </td><td>14    </td><td>0     </td><td>2     </td><td> 60   </td><td> 159  </td><td>1     </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0     </td><td>15.83 </td><td> 0.585</td><td>2     </td><td>8     </td><td>8     </td><td>1.500 </td><td>1     </td><td>1     </td><td> 2    </td><td>0     </td><td>2     </td><td>100   </td><td>   1  </td><td>1     </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>1     </td><td>17.42 </td><td> 6.500</td><td>2     </td><td>3     </td><td>4     </td><td>0.125 </td><td>0     </td><td>0     </td><td> 0    </td><td>0     </td><td>2     </td><td> 60   </td><td> 101  </td><td>0     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & V12 & V13 & V14 & V15\\\\\n",
       "\\hline\n",
       "\t1 & 1      & 22.08  & 11.460 & 2      & 4      & 4      & 1.585  & 0      & 0      &  0     & 1      & 2      & 100    & 1213   & 0     \\\\\n",
       "\t2 & 0      & 22.67  &  7.000 & 2      & 8      & 4      & 0.165  & 0      & 0      &  0     & 0      & 2      & 160    &    1   & 0     \\\\\n",
       "\t3 & 0      & 29.58  &  1.750 & 1      & 4      & 4      & 1.250  & 0      & 0      &  0     & 1      & 2      & 280    &    1   & 0     \\\\\n",
       "\t5 & 1      & 20.17  &  8.170 & 2      & 6      & 4      & 1.960  & 1      & 1      & 14     & 0      & 2      &  60    &  159   & 1     \\\\\n",
       "\t6 & 0      & 15.83  &  0.585 & 2      & 8      & 8      & 1.500  & 1      & 1      &  2     & 0      & 2      & 100    &    1   & 1     \\\\\n",
       "\t7 & 1      & 17.42  &  6.500 & 2      & 3      & 4      & 0.125  & 0      & 0      &  0     & 0      & 2      &  60    &  101   & 0     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 | V12 | V13 | V14 | V15 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1      | 22.08  | 11.460 | 2      | 4      | 4      | 1.585  | 0      | 0      |  0     | 1      | 2      | 100    | 1213   | 0      |\n",
       "| 2 | 0      | 22.67  |  7.000 | 2      | 8      | 4      | 0.165  | 0      | 0      |  0     | 0      | 2      | 160    |    1   | 0      |\n",
       "| 3 | 0      | 29.58  |  1.750 | 1      | 4      | 4      | 1.250  | 0      | 0      |  0     | 1      | 2      | 280    |    1   | 0      |\n",
       "| 5 | 1      | 20.17  |  8.170 | 2      | 6      | 4      | 1.960  | 1      | 1      | 14     | 0      | 2      |  60    |  159   | 1      |\n",
       "| 6 | 0      | 15.83  |  0.585 | 2      | 8      | 8      | 1.500  | 1      | 1      |  2     | 0      | 2      | 100    |    1   | 1      |\n",
       "| 7 | 1      | 17.42  |  6.500 | 2      | 3      | 4      | 0.125  | 0      | 0      |  0     | 0      | 2      |  60    |  101   | 0      |\n",
       "\n"
      ],
      "text/plain": [
       "  V1 V2    V3     V4 V5 V6 V7    V8 V9 V10 V11 V12 V13 V14  V15\n",
       "1 1  22.08 11.460 2  4  4  1.585 0  0   0  1   2   100 1213 0  \n",
       "2 0  22.67  7.000 2  8  4  0.165 0  0   0  0   2   160    1 0  \n",
       "3 0  29.58  1.750 1  4  4  1.250 0  0   0  1   2   280    1 0  \n",
       "5 1  20.17  8.170 2  6  4  1.960 1  1  14  0   2    60  159 1  \n",
       "6 0  15.83  0.585 2  8  8  1.500 1  1   2  0   2   100    1 1  \n",
       "7 1  17.42  6.500 2  3  4  0.125 0  0   0  0   2    60  101 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>537</th><td>1    </td><td>33.75</td><td>2.750</td><td>2    </td><td>3    </td><td>5    </td><td>0.000</td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>2    </td><td>180  </td><td>1    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>136</th><td>0    </td><td>38.33</td><td>4.415</td><td>2    </td><td>8    </td><td>4    </td><td>0.125</td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>2    </td><td>160  </td><td>1    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>671</th><td>0    </td><td>37.75</td><td>5.500</td><td>2    </td><td>11   </td><td>4    </td><td>0.125</td><td>1    </td><td>0    </td><td>0    </td><td>1    </td><td>2    </td><td>228  </td><td>1    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>659</th><td>0    </td><td>17.67</td><td>0.000</td><td>1    </td><td>5    </td><td>1    </td><td>0.000</td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>2    </td><td> 86  </td><td>1    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>613</th><td>1    </td><td>26.17</td><td>0.250</td><td>2    </td><td>3    </td><td>5    </td><td>0.000</td><td>1    </td><td>0    </td><td>0    </td><td>1    </td><td>2    </td><td>  0  </td><td>1    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>385</th><td>0    </td><td>41.17</td><td>6.500</td><td>2    </td><td>11   </td><td>4    </td><td>0.500</td><td>1    </td><td>1    </td><td>3    </td><td>1    </td><td>2    </td><td>145  </td><td>1    </td><td>1    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & V12 & V13 & V14 & V15\\\\\n",
       "\\hline\n",
       "\t537 & 1     & 33.75 & 2.750 & 2     & 3     & 5     & 0.000 & 0     & 0     & 0     & 0     & 2     & 180   & 1     & 0    \\\\\n",
       "\t136 & 0     & 38.33 & 4.415 & 2     & 8     & 4     & 0.125 & 0     & 0     & 0     & 0     & 2     & 160   & 1     & 0    \\\\\n",
       "\t671 & 0     & 37.75 & 5.500 & 2     & 11    & 4     & 0.125 & 1     & 0     & 0     & 1     & 2     & 228   & 1     & 1    \\\\\n",
       "\t659 & 0     & 17.67 & 0.000 & 1     & 5     & 1     & 0.000 & 0     & 0     & 0     & 0     & 2     &  86   & 1     & 0    \\\\\n",
       "\t613 & 1     & 26.17 & 0.250 & 2     & 3     & 5     & 0.000 & 1     & 0     & 0     & 1     & 2     &   0   & 1     & 1    \\\\\n",
       "\t385 & 0     & 41.17 & 6.500 & 2     & 11    & 4     & 0.500 & 1     & 1     & 3     & 1     & 2     & 145   & 1     & 1    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 | V12 | V13 | V14 | V15 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 537 | 1     | 33.75 | 2.750 | 2     | 3     | 5     | 0.000 | 0     | 0     | 0     | 0     | 2     | 180   | 1     | 0     |\n",
       "| 136 | 0     | 38.33 | 4.415 | 2     | 8     | 4     | 0.125 | 0     | 0     | 0     | 0     | 2     | 160   | 1     | 0     |\n",
       "| 671 | 0     | 37.75 | 5.500 | 2     | 11    | 4     | 0.125 | 1     | 0     | 0     | 1     | 2     | 228   | 1     | 1     |\n",
       "| 659 | 0     | 17.67 | 0.000 | 1     | 5     | 1     | 0.000 | 0     | 0     | 0     | 0     | 2     |  86   | 1     | 0     |\n",
       "| 613 | 1     | 26.17 | 0.250 | 2     | 3     | 5     | 0.000 | 1     | 0     | 0     | 1     | 2     |   0   | 1     | 1     |\n",
       "| 385 | 0     | 41.17 | 6.500 | 2     | 11    | 4     | 0.500 | 1     | 1     | 3     | 1     | 2     | 145   | 1     | 1     |\n",
       "\n"
      ],
      "text/plain": [
       "    V1 V2    V3    V4 V5 V6 V7    V8 V9 V10 V11 V12 V13 V14 V15\n",
       "537 1  33.75 2.750 2  3  5  0.000 0  0  0   0   2   180 1   0  \n",
       "136 0  38.33 4.415 2  8  4  0.125 0  0  0   0   2   160 1   0  \n",
       "671 0  37.75 5.500 2  11 4  0.125 1  0  0   1   2   228 1   1  \n",
       "659 0  17.67 0.000 1  5  1  0.000 0  0  0   0   2    86 1   0  \n",
       "613 1  26.17 0.250 2  3  5  0.000 1  0  0   1   2     0 1   1  \n",
       "385 0  41.17 6.500 2  11 4  0.500 1  1  3   1   2   145 1   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(myData[train,])\n",
    "head(myData[test,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are creating a generalized linear model. After that, we are classifying our predictions for a certain probability value (setted as 0.7 in this example), then creating a confusion matrix in order to test model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for approved credit applications for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "         real\n",
       "predicted  0  1\n",
       "        0 83 27\n",
       "        1 15 47\n",
       "                                         \n",
       "               Accuracy : 0.7558         \n",
       "                 95% CI : (0.6846, 0.818)\n",
       "    No Information Rate : 0.5698         \n",
       "    P-Value [Acc > NIR] : 2.887e-07      \n",
       "                                         \n",
       "                  Kappa : 0.4918         \n",
       " Mcnemar's Test P-Value : 0.08963        \n",
       "                                         \n",
       "            Sensitivity : 0.8469         \n",
       "            Specificity : 0.6351         \n",
       "         Pos Pred Value : 0.7545         \n",
       "         Neg Pred Value : 0.7581         \n",
       "             Prevalence : 0.5698         \n",
       "         Detection Rate : 0.4826         \n",
       "   Detection Prevalence : 0.6395         \n",
       "      Balanced Accuracy : 0.7410         \n",
       "                                         \n",
       "       'Positive' Class : 0              \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- glm(V15 ~ V2 + V3 + V7 + V10 + V13 + V14, data=myData[train,], binomial)\n",
    "oddsratio <- exp(predict(model,myData[test,]))\n",
    "predicted <- ifelse(oddsratio > 0.75,1,0)\n",
    "confusionMatrix(table(predicted,real=myData[test,15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statlog data set shows us that numerical columns give an accuracy between %75 and %80. In order to determine signifiance of given features, let's take a look at anova and summary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Df</th><th scope=col>Deviance</th><th scope=col>Resid. Df</th><th scope=col>Resid. Dev</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>NULL</th><td>NA          </td><td>          NA</td><td>517         </td><td>712.8716    </td></tr>\n",
       "\t<tr><th scope=row>V2</th><td> 1          </td><td>16.447507965</td><td>516         </td><td>696.4241    </td></tr>\n",
       "\t<tr><th scope=row>V3</th><td> 1          </td><td>13.945282898</td><td>515         </td><td>682.4788    </td></tr>\n",
       "\t<tr><th scope=row>V7</th><td> 1          </td><td>46.769040176</td><td>514         </td><td>635.7098    </td></tr>\n",
       "\t<tr><th scope=row>V10</th><td> 1          </td><td>94.133793729</td><td>513         </td><td>541.5760    </td></tr>\n",
       "\t<tr><th scope=row>V13</th><td> 1          </td><td> 0.005326222</td><td>512         </td><td>541.5706    </td></tr>\n",
       "\t<tr><th scope=row>V14</th><td> 1          </td><td>32.304871721</td><td>511         </td><td>509.2658    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Df & Deviance & Resid. Df & Resid. Dev\\\\\n",
       "\\hline\n",
       "\tNULL & NA           &           NA & 517          & 712.8716    \\\\\n",
       "\tV2 &  1           & 16.447507965 & 516          & 696.4241    \\\\\n",
       "\tV3 &  1           & 13.945282898 & 515          & 682.4788    \\\\\n",
       "\tV7 &  1           & 46.769040176 & 514          & 635.7098    \\\\\n",
       "\tV10 &  1           & 94.133793729 & 513          & 541.5760    \\\\\n",
       "\tV13 &  1           &  0.005326222 & 512          & 541.5706    \\\\\n",
       "\tV14 &  1           & 32.304871721 & 511          & 509.2658    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Df | Deviance | Resid. Df | Resid. Dev |\n",
       "|---|---|---|---|---|\n",
       "| NULL | NA           |           NA | 517          | 712.8716     |\n",
       "| V2 |  1           | 16.447507965 | 516          | 696.4241     |\n",
       "| V3 |  1           | 13.945282898 | 515          | 682.4788     |\n",
       "| V7 |  1           | 46.769040176 | 514          | 635.7098     |\n",
       "| V10 |  1           | 94.133793729 | 513          | 541.5760     |\n",
       "| V13 |  1           |  0.005326222 | 512          | 541.5706     |\n",
       "| V14 |  1           | 32.304871721 | 511          | 509.2658     |\n",
       "\n"
      ],
      "text/plain": [
       "     Df Deviance     Resid. Df Resid. Dev\n",
       "NULL NA           NA 517       712.8716  \n",
       "V2    1 16.447507965 516       696.4241  \n",
       "V3    1 13.945282898 515       682.4788  \n",
       "V7    1 46.769040176 514       635.7098  \n",
       "V10   1 94.133793729 513       541.5760  \n",
       "V13   1  0.005326222 512       541.5706  \n",
       "V14   1 32.304871721 511       509.2658  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = V15 ~ V2 + V3 + V7 + V10 + V13 + V14, family = binomial, \n",
       "    data = myData[train, ])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-3.2209  -0.7414  -0.6253   0.7374   1.8930  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.6214593  0.3627757  -4.470 7.84e-06 ***\n",
       "V2           0.0029413  0.0102428   0.287 0.773993    \n",
       "V3           0.0246464  0.0228809   1.077 0.281408    \n",
       "V7           0.2365017  0.0493494   4.792 1.65e-06 ***\n",
       "V10          0.3121393  0.0489821   6.373 1.86e-10 ***\n",
       "V13         -0.0003077  0.0006639  -0.463 0.643026    \n",
       "V14          0.0004866  0.0001350   3.604 0.000314 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 712.87  on 517  degrees of freedom\n",
       "Residual deviance: 509.27  on 511  degrees of freedom\n",
       "AIC: 523.27\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(model)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's apply logistic regression on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "         real\n",
       "predicted  0  1\n",
       "        0 76 16\n",
       "        1 16 64\n",
       "                                          \n",
       "               Accuracy : 0.814           \n",
       "                 95% CI : (0.7476, 0.8691)\n",
       "    No Information Rate : 0.5349          \n",
       "    P-Value [Acc > NIR] : 1.689e-14       \n",
       "                                          \n",
       "                  Kappa : 0.6261          \n",
       " Mcnemar's Test P-Value : 1               \n",
       "                                          \n",
       "            Sensitivity : 0.8261          \n",
       "            Specificity : 0.8000          \n",
       "         Pos Pred Value : 0.8261          \n",
       "         Neg Pred Value : 0.8000          \n",
       "             Prevalence : 0.5349          \n",
       "         Detection Rate : 0.4419          \n",
       "   Detection Prevalence : 0.5349          \n",
       "      Balanced Accuracy : 0.8130          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- nrow(myData)\n",
    "test <- sample(1:n, n*0.25)\n",
    "train <- -test\n",
    "model <- glm(V15 ~ . , data=myData[train,], binomial)\n",
    "oddsratio <- exp(predict(model,myData[test,]))\n",
    "predicted <- ifelse(oddsratio > 0.7,1,0)\n",
    "confusionMatrix(table(predicted,real=myData[test,15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = V15 ~ ., family = binomial, data = myData[train, \n",
       "    ])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.6139  -0.2706  -0.0849   0.2870   3.3813  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -7.065e+00  1.279e+00  -5.523 3.33e-08 ***\n",
       "V11         -1.414e-01  3.854e-01  -0.367 0.713772    \n",
       "V2           2.314e-02  1.669e-02   1.387 0.165570    \n",
       "V3          -3.580e-02  3.509e-02  -1.020 0.307598    \n",
       "V42          1.484e+00  4.616e-01   3.215 0.001302 ** \n",
       "V43          3.249e+01  2.230e+03   0.015 0.988375    \n",
       "V52         -9.139e+00  1.275e+03  -0.007 0.994282    \n",
       "V53         -9.662e+00  1.275e+03  -0.008 0.993954    \n",
       "V54         -9.929e+00  1.275e+03  -0.008 0.993788    \n",
       "V55          2.328e+00  7.674e+00   0.303 0.761616    \n",
       "V56         -9.878e+00  1.275e+03  -0.008 0.993820    \n",
       "V57         -1.014e+01  1.275e+03  -0.008 0.993654    \n",
       "V58         -8.864e+00  1.275e+03  -0.007 0.994454    \n",
       "V59         -9.235e+00  1.275e+03  -0.007 0.994221    \n",
       "V510        -7.172e+00  1.275e+03  -0.006 0.995512    \n",
       "V511        -9.180e+00  1.275e+03  -0.007 0.994256    \n",
       "V512        -2.557e+01  1.479e+03  -0.017 0.986206    \n",
       "V513        -8.287e+00  1.275e+03  -0.006 0.994815    \n",
       "V514        -5.606e+00  1.275e+03  -0.004 0.996493    \n",
       "V62          1.002e+01  1.275e+03   0.008 0.993733    \n",
       "V63         -1.767e+00  7.779e+00  -0.227 0.820276    \n",
       "V64          1.177e+01  1.275e+03   0.009 0.992638    \n",
       "V65          1.065e+01  1.275e+03   0.008 0.993335    \n",
       "V67          2.920e+01  1.479e+03   0.020 0.984248    \n",
       "V68          1.237e+01  1.275e+03   0.010 0.992260    \n",
       "V69          3.243e+00  1.275e+03   0.003 0.997971    \n",
       "V7          -1.479e-02  6.521e-02  -0.227 0.820565    \n",
       "V81          4.140e+00  4.619e-01   8.964  < 2e-16 ***\n",
       "V91          6.298e-01  4.968e-01   1.268 0.204904    \n",
       "V10          1.571e-01  8.594e-02   1.827 0.067637 .  \n",
       "V111        -3.069e-01  3.496e-01  -0.878 0.380038    \n",
       "V122        -1.021e-01  5.366e-01  -0.190 0.849090    \n",
       "V123         4.043e+00  1.317e+00   3.071 0.002135 ** \n",
       "V13         -3.553e-03  1.120e-03  -3.172 0.001513 ** \n",
       "V14          9.293e-04  2.447e-04   3.798 0.000146 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 710.17  on 517  degrees of freedom\n",
       "Residual deviance: 258.35  on 483  degrees of freedom\n",
       "AIC: 328.35\n",
       "\n",
       "Number of Fisher Scoring iterations: 16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis and Data Reconfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data adjustments for 5th column because it created some problems about splitting dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distance <- dist(myData[,c(\"V2\",\"V3\",\"V7\",\"V10\",\"V13\",\"V14\")])\n",
    "cluster <- hclust(distance)\n",
    "#plot(cluster, label= myData$v15)\n",
    "sd <- split(myData$V5,cutree(cluster, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4   5   6   7   8   9  10  11  12  13  14 \n",
      " 52  30  59  51  10  54  37 144  64  23  77   2  40  38 \n",
      "\n",
      " 1  2  3  4  5  6  7  8  9 10 11 12 13 14 \n",
      " 0  0  0  0  0  0  1  2  0  1  1  1  0  0 \n",
      "\n",
      " 1  2  3  4  5  6  7  8  9 10 11 12 13 14 \n",
      " 0  0  0  0  0  0  0  0  0  1  0  0  1  0 \n",
      "\n",
      " 1  2  3  4  5  6  7  8  9 10 11 12 13 14 \n",
      " 1  0  0  0  0  0  0  0  0  0  0  0  0  0 \n"
     ]
    }
   ],
   "source": [
    "for(i in 1:4) {\n",
    "    print(table(sd[i]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treeModel.model <- rpart(V15 ~ V5, data=myData, method='class')\n",
    "rpart.plot(treeModel.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
